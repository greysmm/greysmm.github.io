### Project Starlight

Welcome to Project Starlight! You can see the actual deployment of the project at [greysmm.github.io/starlight](https://greysmm.github.io/starlight). I started this project because I was curious how viable it was to train a diffusion model that could perform inference (i.e. generate images) in the user's browser, without any server side assistance as basically all current web diffusion builds seem to be doing. As is to be expected, I had to make a lot of sacrifices with the quality of the model in order to get it to the point where it would not crash the user's browser, though much of the complexity comes from the fact that I wanted to generate not just one but several stars, and to have them twinkle as real stars do.

So how does this actually work? Well, every time the model generates a star, it is actually generating a batch of different stars; I trained the model with downscaled resolution images of real stars for a relatively low number of epochs, and the model also did not have many trainable parameters, thus these stars just look very similar while retaining enough variance to apparently "twinkle" as each star is swapped out for the next at a high rate (you can essentially think of each star in the batch as a frame of a video or gif). The diffusion process makes it so that no generated star is the same, and I do some post processing to make the stars look better (e.g. swapping around RGB channels so that not all of the stars are the same color). The star is then placed at a random spot on the container div.

Important assets: the src directory holds all of the code for the web page. The training directory has a training script that can be called using `pnpm train` in this directory. The api has the trained model that I use for the web page.